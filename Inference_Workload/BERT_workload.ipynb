{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36290e74-6acd-4cc9-8383-32d36d36855d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ray==2.36.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38a15a1-2787-491d-96c1-a84ae9169fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ray[client]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d606ff6c-f8db-4bd2-9a1d-b1495d244feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab8fd85-ff50-4be0-bfa8-298851476db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2703b7b5-7979-4b82-b797-4bc041da92ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6b21c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e916a7e0-245f-4318-8b11-ac0a2b155088",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f51658-0ac9-485b-a632-c622cc0c2452",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "runtime_env = {\"pip\": [\"torch\",\"IPython\",\"transformers\",\"filelock\"]}\n",
    "# ray://${RAYCLUSTER_HEAD_SVC}.${NAMESPACE}.svc.cluster.local:${RAY_CLIENT_PORT}\n",
    "ray.init(address=\"ray://raycluster1-kuberay-head-svc.default.svc.cluster.local:10001\", runtime_env=runtime_env)\n",
    "print(ray.cluster_resources())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe81403-1748-4fba-84bc-ac196df01a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79177b46-e400-415b-a92e-98f6b0b168f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import torch\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "def load_model():\n",
    "    \"\"\"Load the BERT model and tokenizer on GPU.\"\"\"\n",
    "    model_name = \"bert-base-uncased\"\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "    model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)  # Binary classification example\n",
    "    model.to(device).eval()\n",
    "\n",
    "    return tokenizer, model, device\n",
    "\n",
    "def augment_sentence(sentence):\n",
    "    \"\"\"Create minor variations of a sentence for dataset augmentation.\"\"\"\n",
    "    synonyms = {\n",
    "        \"amazing\": [\"incredible\", \"fantastic\", \"awesome\"],\n",
    "        \"disappointing\": [\"unsatisfactory\", \"frustrating\", \"terrible\"],\n",
    "        \"great\": [\"wonderful\", \"excellent\", \"superb\"],\n",
    "        \"worst\": [\"horrible\", \"awful\", \"terrible\"],\n",
    "        \"fantastic\": [\"phenomenal\", \"spectacular\", \"superb\"]\n",
    "    }\n",
    "    \n",
    "    words = sentence.split()\n",
    "    for i in range(len(words)):\n",
    "        if words[i] in synonyms and random.random() > 0.5:\n",
    "            words[i] = random.choice(synonyms[words[i]])\n",
    "\n",
    "    if random.random() > 0.7:\n",
    "        random.shuffle(words)\n",
    "\n",
    "    return \" \".join(words)\n",
    "\n",
    "def generate_large_dataset(num_samples=100000):\n",
    "    \"\"\"Generate a large dataset with sentence variations.\"\"\"\n",
    "    base_sentences = [\n",
    "        \"The product is amazing and works flawlessly.\",\n",
    "        \"I didn't like the service at all. It was disappointing.\",\n",
    "        \"The experience was great! I highly recommend it.\",\n",
    "        \"The worst purchase I have ever made. Never again.\",\n",
    "        \"Absolutely fantastic! I loved every bit of it.\"\n",
    "    ]\n",
    "    \n",
    "    dataset = [augment_sentence(random.choice(base_sentences)) for _ in range(num_samples)]\n",
    "    return dataset\n",
    "\n",
    "@ray.remote(num_gpus=1)  # Assign GPU to each worker\n",
    "def run_inference_worker(text_list, batch_size=512):\n",
    "    \"\"\"Run inference on a subset of data on a GPU worker.\"\"\"\n",
    "    tokenizer, model, device = load_model()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    predictions = []\n",
    "\n",
    "    for i in range(0, len(text_list), batch_size):\n",
    "        batch_texts = text_list[i:i + batch_size]\n",
    "        inputs = tokenizer(batch_texts, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "        batch_predictions = torch.argmax(probabilities, dim=-1).tolist()\n",
    "        predictions.extend(batch_predictions)\n",
    "\n",
    "        # print(f\"Processed batch {i // batch_size + 1}/{len(text_list) // batch_size} \")\n",
    "\n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    print(f\"Worker finished processing {len(text_list)} samples in {duration:.2f} seconds\")\n",
    "    \n",
    "    return predictions, duration\n",
    "\n",
    "def run_distributed_inference(dataset, num_workers=4, batch_size=1024):\n",
    "    \"\"\"Distribute the dataset across multiple workers using Ray.\"\"\"\n",
    "    chunk_size = len(dataset) // num_workers\n",
    "    dataset_chunks = [dataset[i * chunk_size:(i + 1) * chunk_size] for i in range(num_workers)]\n",
    "\n",
    "    # Distribute workload to workers\n",
    "    futures = [run_inference_worker.remote(chunk, batch_size) for chunk in dataset_chunks]\n",
    "    \n",
    "    # Gather results from all workers\n",
    "    results = ray.get(futures)\n",
    "    \n",
    "    # Extract predictions and durations\n",
    "    final_predictions = [pred for sublist, _ in results for pred in sublist]  # Flatten the list\n",
    "    durations = [duration for _, duration in results]\n",
    "\n",
    "    print(f\"Total processed samples: {len(final_predictions)}\")\n",
    "    print(f\"Total duration for this run: {sum(durations):.2f} seconds\")\n",
    "\n",
    "    return sum(durations)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dataset = generate_large_dataset(num_samples=200000)  # Increased dataset size\n",
    "    \n",
    "    # Run the workload 25 times and measure duration\n",
    "    durations = []\n",
    "    total_start_time = time.time()\n",
    "    workloads = 25\n",
    "    \n",
    "    for run in range(workloads):\n",
    "        print(f\"Starting run {run + 1}/{workloads}\")\n",
    "        start_time = time.time()\n",
    "        duration = run_distributed_inference(dataset, num_workers=4, batch_size=1024)\n",
    "        durations.append(duration)\n",
    "        print(f\"Run {run + 1} completed in {duration:.2f} seconds\\n\")\n",
    "    \n",
    "    total_end_time = time.time()\n",
    "    total_duration = total_end_time - total_start_time\n",
    "\n",
    "    # Print summary\n",
    "    print(f\"\\n=== Performance Summary ===\")\n",
    "    print(f\"Total duration for {workloads} runs: {total_duration:.2f} seconds\")\n",
    "    print(f\"Average duration per run: {total_duration / workloads:.2f} seconds\")\n",
    "\n",
    "    # Save durations to CSV\n",
    "    df = pd.DataFrame({\"Run\": list(range(1, workloads+1)), \"Duration (seconds)\": durations})\n",
    "    df.to_csv(\"run_durations.csv\", index=False)\n",
    "    print(\"Durations saved to 'run_durations.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
